{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d03f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing: C:\\Users\\vyach\\Documents\\UN Law Research\\PDF Reader\\RAG_LLM\\data\\Switzerland_CRC_C_98_D_153_2021.pdf ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vyach\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1630: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Admissibility Section Found.\n",
      "üîç Checking for Parent Involvement...\n",
      "‚úÖ Parent Involvement: **Yes**\n",
      "\n",
      "--- Processing: C:\\Users\\vyach\\Documents\\UN Law Research\\PDF Reader\\RAG_LLM\\data\\Belgium_CRC_C_98_D_143_2021.pdf ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vyach\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1630: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Admissibility Section Found.\n",
      "üîç Checking for Parent Involvement...\n",
      "‚úÖ Parent Involvement: Based on the provided text, the claim was brought by S.M. and A.T.M. on behalf of their children, F.M. and H.M. The text explicitly states that the communication was submitted by S.M. and A.T.M., who are the parents of the children. Therefore, it is clear that the claim is brought by parents.\n",
      "‚úÖ Data successfully saved to UN_Human_Rights_Communications.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>communication_submitted_by</th>\n",
       "      <th>alleged_victims</th>\n",
       "      <th>state_party</th>\n",
       "      <th>date_of_communication</th>\n",
       "      <th>date_of_adoption_of_views</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>articles_of_convention</th>\n",
       "      <th>articles_of_optional_protocol</th>\n",
       "      <th>nationality_of_victim</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>reason_for_outcome</th>\n",
       "      <th>violation_outcome</th>\n",
       "      <th>articles_violated</th>\n",
       "      <th>claim_brought_by_parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland_CRC_C_98_D_153_2021.pdf</td>\n",
       "      <td>A.M. and E.P. (represented by counsel, Benedik...</td>\n",
       "      <td>The authors</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>20 July 2021</td>\n",
       "      <td>27 January 2025</td>\n",
       "      <td>Children‚Äôs right to visit and contact their mo...</td>\n",
       "      <td>2, 3, 9 and 12</td>\n",
       "      <td>7 (d), (e), (f) and (h)</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>admissible</td>\n",
       "      <td>Detected via keyword match</td>\n",
       "      <td>** Violation</td>\n",
       "      <td>** Articles 3 and 12</td>\n",
       "      <td>**Yes**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgium_CRC_C_98_D_143_2021.pdf</td>\n",
       "      <td>S.M. and A.T.M. (represented by counsel, Sylvi...</td>\n",
       "      <td>S.M., F.M. and H.M.</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>10 December 2020</td>\n",
       "      <td>24 January 2025</td>\n",
       "      <td>Return of two children, one of whom is disable...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>7 (c), (e) and (f)</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>inadmissible</td>\n",
       "      <td>Detected via keyword match</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Based on the provided text, the claim was brou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  \\\n",
       "0  Switzerland_CRC_C_98_D_153_2021.pdf   \n",
       "1      Belgium_CRC_C_98_D_143_2021.pdf   \n",
       "\n",
       "                          communication_submitted_by      alleged_victims  \\\n",
       "0  A.M. and E.P. (represented by counsel, Benedik...          The authors   \n",
       "1  S.M. and A.T.M. (represented by counsel, Sylvi...  S.M., F.M. and H.M.   \n",
       "\n",
       "   state_party date_of_communication date_of_adoption_of_views  \\\n",
       "0  Switzerland          20 July 2021           27 January 2025   \n",
       "1      Belgium      10 December 2020           24 January 2025   \n",
       "\n",
       "                                      subject_matter articles_of_convention  \\\n",
       "0  Children‚Äôs right to visit and contact their mo...         2, 3, 9 and 12   \n",
       "1  Return of two children, one of whom is disable...                    N/A   \n",
       "\n",
       "  articles_of_optional_protocol nationality_of_victim  case_outcome  \\\n",
       "0       7 (d), (e), (f) and (h)           Switzerland    admissible   \n",
       "1            7 (c), (e) and (f)               Algeria  inadmissible   \n",
       "\n",
       "           reason_for_outcome violation_outcome     articles_violated  \\\n",
       "0  Detected via keyword match      ** Violation  ** Articles 3 and 12   \n",
       "1  Detected via keyword match               N/A                   N/A   \n",
       "\n",
       "                            claim_brought_by_parents  \n",
       "0                                            **Yes**  \n",
       "1  Based on the provided text, the claim was brou...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Imports & Setup ---\n",
    "import os, uuid\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-ada-002\", openai_api_key=OPENAI_API_KEY)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "class ExtractedInfo(BaseModel):\n",
    "    communication_submitted_by: str\n",
    "    alleged_victims: str\n",
    "    state_party: str\n",
    "    date_of_communication: str\n",
    "    date_of_adoption_of_views: str\n",
    "    subject_matter: str\n",
    "    articles_of_convention: str\n",
    "    articles_of_optional_protocol: str\n",
    "    nationality_of_victim: str\n",
    "\n",
    "\n",
    "# --- Prompts ---\n",
    "MAIN_PROMPT = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "Extract answers exactly as they are written in the document. \n",
    "Do NOT paraphrase, shorten, or summarize any part of the response.\n",
    "\n",
    "Extract the following fields from the context:\n",
    "- communication_submitted_by (from the field labelled \"Communication submitted by:\" ‚Äî do not confuse this with \"Alleged victims\" or similar entries. Include the name of the legal representative if mentioned.)\n",
    "- alleged_victims (from \"Alleged victim(s):\" or \"Alleged victim:\")\n",
    "- state_party (from \"State Party:\")\n",
    "- date_of_communication (from \"Date of communication:\")\n",
    "- date_of_adoption_of_views (from either \"Date of adoption of Views:\" or \"Date of adoption of decision:\")\n",
    "- subject_matter (from \"Subject matter:\")\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the following instruction: {question}\n",
    "\"\"\"\n",
    "main_prompt_template = ChatPromptTemplate.from_template(MAIN_PROMPT)\n",
    "\n",
    "# --- Violation Prompt ---\n",
    "VIOLATION_PROMPT = \"\"\"\n",
    "You are an assistant extracting legal decision outcomes from UN human rights communications.\n",
    "\n",
    "Your task is to determine the *violation outcome* and the *articles violated*.\n",
    "\n",
    "Extract the following two fields:\n",
    "\n",
    "1. Violation Outcome:\n",
    "- \"violation\" ‚Äî if the Committee found that a violation of any article occurred.\n",
    "- \"no violation\" ‚Äî if the case proceeded to merits and no violation was found.\n",
    "- \"N/A\" ‚Äî if the case was entirely inadmissible or discontinued before the merits.\n",
    "\n",
    "2. Articles Violated:\n",
    "- List the exact articles (e.g., \"article 3\", \"article 24\") that were found to be violated.\n",
    "- If none or not applicable, return \"N/A\".\n",
    "\n",
    "Here is the text:\n",
    "\\\"\\\"\\\"{context}\\\"\\\"\\\"    \n",
    "\"\"\"\n",
    "violation_prompt_template = ChatPromptTemplate.from_template(VIOLATION_PROMPT)\n",
    "\n",
    "# --- GPT Violation Call ---\n",
    "def extract_violation_section(text):\n",
    "    \"\"\"\n",
    "    Extract the specific section where the decision on violation is made.\n",
    "    Typically, this is found under \"Consideration of the Merits\", \"Findings\", or \"Conclusions\".\n",
    "    \"\"\"\n",
    "    start_keywords = [\n",
    "        \"Consideration of the Merits\",\n",
    "        \"Findings\",\n",
    "        \"Conclusions\",\n",
    "        \"Decision\"\n",
    "    ]\n",
    "    end_keywords = [\n",
    "        \"Recommendations\",\n",
    "        \"Follow-up\",\n",
    "        \"Implementation\"\n",
    "    ]\n",
    "\n",
    "    start_idx, end_idx = None, None\n",
    "\n",
    "    for keyword in start_keywords:\n",
    "        start_idx = text.lower().find(keyword.lower())\n",
    "        if start_idx != -1:\n",
    "            break\n",
    "\n",
    "    for keyword in end_keywords:\n",
    "        end_idx = text.lower().find(keyword.lower(), start_idx)\n",
    "        if end_idx != -1:\n",
    "            break\n",
    "\n",
    "    if start_idx is not None and end_idx is not None:\n",
    "        return text[start_idx:end_idx]\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def classify_violation_with_gpt(text):\n",
    "    \"\"\"\n",
    "    Uses GPT to extract the final determination of violation from the specified section of the document.\n",
    "    \"\"\"\n",
    "    violation_section = extract_violation_section(text)\n",
    "    \n",
    "    if not violation_section.strip():\n",
    "        return \"N/A\", \"N/A\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant specializing in extracting human rights violations.\n",
    "    Based on the following section, determine the *violation outcome* and list the *articles violated*.\n",
    "\n",
    "    - \"violation\" if the Committee explicitly finds a violation.\n",
    "    - \"no violation\" if the Committee explicitly finds there was no violation.\n",
    "    - \"N/A\" if it is unclear or not stated.\n",
    "\n",
    "    Also, list the exact articles if there was a violation, otherwise respond with \"N/A\".\n",
    "\n",
    "    Here is the text:\n",
    "    \\\"\\\"\\\"{violation_section}\\\"\\\"\\\"       \n",
    "    Respond with:\n",
    "    Violation Outcome: <violation / no violation / N/A>\n",
    "    Articles Violated: <list of articles or N/A>\n",
    "    \"\"\"\n",
    "    response = llm.predict(prompt)\n",
    "\n",
    "    # Safe Parsing\n",
    "    try:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        violation_outcome = lines[0].replace(\"Violation Outcome: \", \"\").strip()\n",
    "        articles_violated = lines[1].replace(\"Articles Violated: \", \"\").strip()\n",
    "    except IndexError:\n",
    "        violation_outcome = \"N/A\"\n",
    "        articles_violated = \"N/A\"\n",
    "\n",
    "    return violation_outcome, articles_violated\n",
    "\n",
    "\n",
    "# --- Admissibility Extraction ---\n",
    "def extract_admissibility_section(text):\n",
    "    start_keywords = [\"Consideration of Admissibility\", \"Admissibility\", \"Consideration of admissibility\"]\n",
    "    end_keywords = [\"Consideration of the Merits\", \"Merits\", \"Substantive Issues\"]\n",
    "    \n",
    "    start_idx, end_idx = None, None\n",
    "    \n",
    "    for keyword in start_keywords:\n",
    "        start_idx = text.lower().find(keyword.lower())\n",
    "        if start_idx != -1:\n",
    "            break\n",
    "    \n",
    "    for keyword in end_keywords:\n",
    "        end_idx = text.lower().find(keyword.lower(), start_idx)\n",
    "        if end_idx != -1:\n",
    "            break\n",
    "    \n",
    "    if start_idx is not None and end_idx is not None:\n",
    "        return text[start_idx:end_idx]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# --- Nationality Prompt ---\n",
    "NATIONALITY_PROMPT = \"\"\"\n",
    "You are an assistant extracting legal decision outcomes from UN human rights communications.\n",
    "\n",
    "Your task is to determine the *nationality of the victim*.\n",
    "\n",
    "Extract the following field:\n",
    "\n",
    "1. Nationality of the Victim:\n",
    "- Look for direct mentions such as \"born in\", \"citizen of\", \"national of\", \"of nationality\", or \"residing in\".\n",
    "- Search for terms like \"originated from,\" \"of [Country] descent,\" or \"originally from.\"\n",
    "- If the text mentions parents' nationalities, use that as a clue.\n",
    "- If multiple nationalities are mentioned, list them.\n",
    "- If you cannot determine it, respond with \"Unknown\".\n",
    "\n",
    "Here is the text:\n",
    "\\\"\\\"\\\"{context}\\\"\\\"\\\"    \n",
    "\"\"\"\n",
    "nationality_prompt_template = ChatPromptTemplate.from_template(NATIONALITY_PROMPT)\n",
    "\n",
    "def classify_nationality_with_gpt(text):\n",
    "    \"\"\"\n",
    "    Uses GPT to extract the nationality of the victim.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant specializing in extracting nationality information.\n",
    "    Based on the following text, determine the *nationality of the victim*.\n",
    "\n",
    "    Respond with:\n",
    "    Nationality of the Victim: <nationality or 'Unknown'>\n",
    "\n",
    "    Clues to look for:\n",
    "    - born in\n",
    "    - citizen of\n",
    "    - national of\n",
    "    - of nationality\n",
    "    - residing in\n",
    "    - originated from\n",
    "    - of [Country] descent\n",
    "    - or any direct mention of country names\n",
    "\n",
    "    Here is the text:\n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "    response = llm.predict(prompt)\n",
    "\n",
    "    nationality = \"Unknown\"  # Default if nothing found\n",
    "    if response:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        if len(lines) > 0:\n",
    "            extracted = lines[0].replace(\"Nationality of the Victim: \", \"\").strip()\n",
    "            if extracted:  # If something was found\n",
    "                nationality = extracted\n",
    "    return nationality\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "PARENT_PROMPT = \"\"\"\n",
    "You are an assistant specializing in legal document analysis.\n",
    "Your task is to determine if the communication is **brought by the parents or guardians** of the victim.\n",
    "\n",
    "Instructions:\n",
    "- Respond with **\"Yes\"** if the text clearly indicates it was submitted by parents or legal guardians.\n",
    "- Respond with **\"No\"** if there is no indication of parents or guardians being the submitters.\n",
    "- If it is ambiguous or unclear, respond with **\"Unclear\"**.\n",
    "\n",
    "Here is the text:\n",
    "\\\"\\\"\\\"{context}\\\"\\\"\\\"    \n",
    "\"\"\"\n",
    "parent_prompt_template = ChatPromptTemplate.from_template(PARENT_PROMPT)\n",
    "\n",
    "def classify_parent_involvement_with_gpt(text):\n",
    "    \"\"\"\n",
    "    Uses GPT to extract if the claim is brought by parents or guardians.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant specializing in determining if the claim was brought by parents or legal guardians.\n",
    "    Based on the following text, determine if the claim is **brought by parents**.\n",
    "\n",
    "    Respond with:\n",
    "    Parent Involvement: <Yes / No / Unclear>\n",
    "\n",
    "    Here is the text:\n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\"    \n",
    "    \"\"\"\n",
    "    response = llm.predict(prompt)\n",
    "\n",
    "    parent_involvement = \"Unclear\"  # Default if nothing found\n",
    "    if response:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        if len(lines) > 0:\n",
    "            extracted = lines[0].replace(\"Parent Involvement: \", \"\").strip()\n",
    "            if extracted:\n",
    "                parent_involvement = extracted\n",
    "    return parent_involvement\n",
    "\n",
    "\n",
    "def extract_parent_involvement(text):\n",
    "    \"\"\"\n",
    "    This function scans the text to identify if the claim is explicitly brought by parents.\n",
    "    If found, it returns \"Yes\" and the specific description; otherwise, it uses GPT for a second check.\n",
    "    \"\"\"\n",
    "    parent_patterns = [\n",
    "        r\"brought by the parents\",\n",
    "        r\"filed by the parents\",\n",
    "        r\"submitted by the parents\",\n",
    "        r\"parents of the victim\",\n",
    "        r\"on behalf of their child\",\n",
    "        r\"on behalf of the minor\",\n",
    "        r\"parents claim\",\n",
    "        r\"submitted by the mother\",\n",
    "        r\"submitted by the father\",\n",
    "        r\"the mother submitted on behalf\",\n",
    "        r\"the father submitted on behalf\",\n",
    "        r\"guardian of the child\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in parent_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return \"Yes\"\n",
    "    \n",
    "    gpt_response = classify_parent_involvement_with_gpt(text)\n",
    "    return gpt_response\n",
    "\n",
    "\n",
    "# --- Main Runner ---\n",
    "def main(pdf_paths):\n",
    "    results = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        print(f\"\\n--- Processing: {pdf_path} ---\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        chunks = text_splitter.split_documents(pages)\n",
    "\n",
    "        vectorstore_path = f\"vectorstores/{os.path.basename(pdf_path).replace('.pdf', '')}\"\n",
    "        vectorstore = create_vectorstore(chunks, vectorstore_path)\n",
    "\n",
    "        main_chain = build_main_chain_with_first_page(pages, vectorstore)\n",
    "        result_main = main_chain.invoke(\"Extract main fields from the document\")\n",
    "        result_dict = result_main.dict()\n",
    "\n",
    "        full_text = \"\\n\".join(page.page_content for page in pages)\n",
    "        admissibility_text = extract_admissibility_section(full_text)\n",
    "        \n",
    "        if admissibility_text:\n",
    "            print(\"‚úÖ Admissibility Section Found.\")\n",
    "            case_outcome, reason = classify_admissibility_with_gpt(admissibility_text)\n",
    "            result_dict[\"case_outcome\"] = case_outcome\n",
    "            result_dict[\"reason_for_outcome\"] = reason\n",
    "        else:\n",
    "            print(\"‚ùå Admissibility Section Not Found.\")\n",
    "            result_dict[\"case_outcome\"] = \"not found\"\n",
    "            result_dict[\"reason_for_outcome\"] = \"N/A\"\n",
    "        \n",
    "        violation_outcome, articles_violated = classify_violation_with_gpt(full_text)\n",
    "        result_dict[\"violation_outcome\"] = violation_outcome\n",
    "        result_dict[\"articles_violated\"] = articles_violated\n",
    "        \n",
    "        result_dict[\"nationality_of_victim\"] = classify_nationality_with_gpt(full_text)\n",
    "\n",
    "        articles_convention = re.search(r\"Articles of the Convention:\\s*(.*)\", full_text, re.IGNORECASE)\n",
    "        if articles_convention:\n",
    "            result_dict[\"articles_of_convention\"] = articles_convention.group(1).strip()\n",
    "        else:\n",
    "            result_dict[\"articles_of_convention\"] = \"N/A\"\n",
    "\n",
    "        articles_optional_protocol = re.search(r\"Articles of the Optional Protocol:\\s*(.*)\", full_text, re.IGNORECASE)\n",
    "        if articles_optional_protocol:\n",
    "            result_dict[\"articles_of_optional_protocol\"] = articles_optional_protocol.group(1).strip()\n",
    "        else:\n",
    "            result_dict[\"articles_of_optional_protocol\"] = \"N/A\"\n",
    "\n",
    "        print(\"üîç Checking for Parent Involvement...\")\n",
    "        parent_involvement = extract_parent_involvement(full_text)\n",
    "        result_dict[\"claim_brought_by_parents\"] = parent_involvement\n",
    "        print(f\"‚úÖ Parent Involvement: {parent_involvement}\")\n",
    "\n",
    "        result_dict[\"filename\"] = os.path.basename(pdf_path)\n",
    "        results.append(result_dict)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    from IPython.display import display\n",
    "    display(df)\n",
    "\n",
    "# --- Run ---\n",
    "pdf_files = [\n",
    "    r\"C:\\Users\\vyach\\Documents\\UN Law Research\\PDF Reader\\RAG_LLM\\data\\Switzerland_CRC_C_98_D_153_2021.pdf\",\n",
    "    r\"C:\\Users\\vyach\\Documents\\UN Law Research\\PDF Reader\\RAG_LLM\\data\\Belgium_CRC_C_98_D_143_2021.pdf\",\n",
    "]\n",
    "main(pdf_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c159cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification of the subject matter of UN CRC\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "df = pd.read_excel(\"Final_Data_UN_CRC.xlsx\", sheet_name=\"final_extraction_results\")\n",
    "\n",
    "def classify_subject_matter(subject_text):\n",
    "    if pd.isna(subject_text) or subject_text.strip() == \"\":\n",
    "        return \"N/A\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal assistant categorizing human rights complaint topics for the UN Committee on the Rights of the Child.\n",
    "\n",
    "Classify the following complaint into one or more of the following categories:\n",
    "- Access to education\n",
    "- Immigration detention\n",
    "- Family separation\n",
    "- Statelessness/nationality\n",
    "- Violence/abuse\n",
    "- Health\n",
    "- Other\n",
    "\n",
    "Subject matter:\n",
    "\\\"\\\"\\\"{subject_text}\\\"\\\"\\\"\n",
    "\n",
    "Respond only with a semicolon-separated list of categories.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a legal analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "        return \"Error\"\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"subject_matter_category\"] = df[\"subject_matter\"].progress_apply(classify_subject_matter)\n",
    "\n",
    "output_file = \"UN_CRC_with_Thematic_Categories.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"‚úÖ File saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94062b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification of the reasons for inadmissibility in UN CRC\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "input_file = \"Final_Data_UN_CRC.xlsx\"\n",
    "df = pd.read_excel(input_file, sheet_name=\"final_extraction_results\")\n",
    "\n",
    "def classify_rejection_reason(row):\n",
    "    reason_text = row[\"reason_for_outcome\"]\n",
    "    outcome = str(row[\"case_outcome\"]).strip().lower()\n",
    "\n",
    "    if pd.isna(reason_text) or reason_text.strip() == \"\":\n",
    "        return \"N/A\"\n",
    "\n",
    "    if outcome != \"inadmissible\":\n",
    "        return \"Not applicable\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal assistant categorizing the *reason for inadmissibility* in cases brought before the UN Committee on the Rights of the Child.\n",
    "\n",
    "Classify the reason below into ONE of the following categories:\n",
    "- Lack of jurisdiction\n",
    "- Failure to exhaust domestic remedies\n",
    "- Insufficient substantiation\n",
    "- Incompatibility with the Convention\n",
    "- Duplication (already considered by another international body)\n",
    "- Mootness or best interests of the child\n",
    "- Other procedural reason\n",
    "\n",
    "Reason:\n",
    "\\\"\\\"\\\"{reason_text}\\\"\\\"\\\"\n",
    "\n",
    "Respond only with one category label from the list above.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a legal analyst.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "        return \"Error\"\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"inadmissibility_category\"] = df.progress_apply(classify_rejection_reason, axis=1)\n",
    "\n",
    "output_file = \"UN_CRC_with_Rejection_Categories.xlsx\"\n",
    "df.to_excel(output_file, index=False)\n",
    "print(f\"‚úÖ File saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
